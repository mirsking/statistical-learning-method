# 统计学习方法-第二章 感知机

标签（空格分隔）： 学习笔记

---

## [在线链接](https://www.zybuluo.com/mirsking/note/195076)

**感知机(perceptron)**是二分类的线性分类模型。对应于特征空间的分类超平面。
* 判别模型
* 神经网络与支持向量机的基础


----------
## 模型
1. 输入空间（特征空间）
    $\mathcal{X}\subseteq R^n$
2. 输出空间
    $\mathcal{Y}=\{-1,+1\}$
3. 模型
    $f(x)=\omega\cdot x+b$
    * 模型的假设空间
        $\{f|f(x)=\omega\cdot x+b\}$
    * 模型的几何意义
        方程$\omega\cdot x+b=0$代表分离超平面$S$。


----------


## 策略
假设训练数据集是线性可分的，则感知机的学习目标就是找到上述的分离超平面的参数$\omega, b$。
### 损失函数
* 误分类点的总数
    缺点：损失函数不是$\omega,b$的连续可导函数。
* 误分类点到超平面的总距离（实际上推倒出距离乘以y取反）
    $$-\frac1{||\omega||}\sum_{x_i \in M}y_i(\omega\cdot x_i+b)$$
    其中$M$误分类点的集合。


----------


## 算法
### 随机梯度下降法
* 梯度计算方法
        $$\nabla_\omega L(\omega, b) = - \sum_{x_i \in M} y_ix_i$$
        $$\nabla_b L(\omega,b) = -\sum_{x_i \in M}y_i$$
### 学习算法
* 原始形式

> 输入： 训练数据集 $T=\{(x_1, y_1), (x_2, y_2), ... (x_N, y_N)\}$， 学习率 $\eta$
> 输出： $\omega, b$; $f(x)=sign(\omega\cdot x+b)$

```
// 参数赋初值
Vector omega = omega0;
Vector b = b0;

// 分类正确点的个数，当达到训练数据集的个数时，循环推出
// 该算法要求训练数据集是线性可分的，否则死循环。
// 事实上，只有训练数据集线性可分，该算法才会收敛。
// 收敛性由Novikoff定理可证，详见《统计学习方法》P31
int right_count = 0;
while right_count < T.size
    for (x,y) in T  //遍历训练数据集中的元素
        if y(wx+b) > 0  //分类正确
            right_count += 1;
        else    // 分类错误，按梯度与学习率更新参数值，并将right_count复位，推出for循环
            right_count = 0;
            omega = omega + eta*y*x;
            b = b + eta*y;
            break;
```

* 对偶形式
    * 基本思想
        将$\omega$和$b$表示为实例$x_i$和标记$y_i$的线性组合的形式。
        $$\omega = \sum_{i=1}^N \alpha_i y_i x_i$$
        $$b = \sum_{x=1}^N \alpha_i y_i$$
        其中$\alpha_i = n_i \eta \geq 0$，当$\eta =1$时，$\alpha_i$表示第$i$个实例点由于误分类而进行更新的次数。
        实例点更新次数越多，意味着其距离超平面越近，越难正确分类，对学习结果的影响越大。
    
    * 对偶形式算法
    > 输入：$T, \eta$
    > 输出：$\alpha, b$; $f(x)=sign(\sum_{j=1}^N \alpha_j y_j x_j\cdot x+b)$
```
Vector alpha = 0;
Vector b = 0;

int right_count = 0;
while right_count < T.size
    for i_th (x,y) in T
        omega_tmp = sum( alpha[j]*y[j]*x[j] ) //从向量的角度看，x和y之间是对应相乘，而alpha则是他们乘出来的N个向量的线性组合系数。
        if y*(omega_tmp \cdot x + b) > 0
            right_count += 1;
        else
            right_count = 0;
            alpha[i] = alpha[i] + eta;
            b = b + eta*y;
            break;
```
